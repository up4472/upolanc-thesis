{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f08f55-17e9-4f66-b952-60801d8cc696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:04.463191Z",
     "iopub.status.busy": "2023-05-06T22:57:04.462691Z",
     "iopub.status.idle": "2023-05-06T22:57:04.482708Z",
     "shell.execute_reply": "2023-05-06T22:57:04.482208Z",
     "shell.execute_reply.started": "2023-05-06T22:57:04.463191Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84acd8e-25d9-4238-b0e5-9273e7ec66a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:04.484209Z",
     "iopub.status.busy": "2023-05-06T22:57:04.484209Z",
     "iopub.status.idle": "2023-05-06T22:57:04.498722Z",
     "shell.execute_reply": "2023-05-06T22:57:04.497721Z",
     "shell.execute_reply.started": "2023-05-06T22:57:04.484209Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure source path\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "while not ROOT.endswith('upolanc-thesis') :\n",
    "\tROOT = os.path.abspath(os.path.join(ROOT, os.pardir))\n",
    "\n",
    "\tif len(ROOT) < len('upolanc-thesis') :\n",
    "\t\tif   platform.system() == 'Linux' :\n",
    "\t\t\tROOT = '/d/hpc/home/up4472/workspace/upolanc-thesis'\n",
    "\t\telif platform.system() == 'Windows' :\n",
    "\t\t\tROOT = 'C:\\\\Developer\\\\Workspace\\\\PyCharm\\\\Projects\\\\upolanc-thesis'\n",
    "\t\telse :\n",
    "\t\t\traise ValueError()\n",
    "\n",
    "\t\tprint(f'Warning : could not find correct directory, using default : {ROOT}')\n",
    "\t\tbreak\n",
    "\n",
    "if ROOT not in sys.path :\n",
    "\tsys.path.append(ROOT)\n",
    "\n",
    "os.chdir(ROOT)\n",
    "\n",
    "sys.path.append(os.path.join(ROOT, 'source', 'python', 'bert', 'dnabert', 'src'))\n",
    "sys.path.append(os.path.join(ROOT, 'source', 'python', 'bert', 'dnabert', 'src', 'transformers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92d31bc-301c-46b7-ab48-965a462cc521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:04.499722Z",
     "iopub.status.busy": "2023-05-06T22:57:04.499722Z",
     "iopub.status.idle": "2023-05-06T22:57:07.817576Z",
     "shell.execute_reply": "2023-05-06T22:57:07.816575Z",
     "shell.execute_reply.started": "2023-05-06T22:57:04.499722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "from source.python.bert.bert_constants import MODELS\n",
    "from source.python.bert.bert_constants import MODES\n",
    "from source.python.bert.bert_constants import PRETRAINED_MODELS\n",
    "from source.python.bert.bert_constants import PROCESSORS\n",
    "\n",
    "from source.python.bert.bert_main      import bert_init_args\n",
    "from source.python.bert.bert_main      import bert_init_classes\n",
    "from source.python.bert.bert_main      import bert_train\n",
    "from source.python.bert.bert_main      import bert_evaluate\n",
    "from source.python.bert.bert_main      import bert_predict\n",
    "from source.python.bert.bert_main      import bert_visualize\n",
    "from source.python.bert.bert_main      import bert_ensamble\n",
    "from source.python                     import runtime\n",
    "\n",
    "runtime.set_numpy_format()\n",
    "runtime.set_pandas_format()\n",
    "runtime.set_plot_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430bb6b-342c-49ed-ba1e-c8801389487b",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04602cda-6f5d-4d6b-8ad3-ae2c7b67348f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:07.820078Z",
     "iopub.status.busy": "2023-05-06T22:57:07.819078Z",
     "iopub.status.idle": "2023-05-06T22:57:07.833089Z",
     "shell.execute_reply": "2023-05-06T22:57:07.832088Z",
     "shell.execute_reply.started": "2023-05-06T22:57:07.820078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all possible models\n",
    "\n",
    "def print_possible_models () :\n",
    "\t\"\"\"\n",
    "\tDoc\n",
    "\t\"\"\"\n",
    "\n",
    "\tfor k, v in MODELS.items() :\n",
    "\t\tprint('{:12s} : {:>16s} {:>36s} {:>20s}'.format(k, v[0].__name__, v[1].__name__, v[2].__name__))\n",
    "\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e94974-c96b-47c2-8329-3024e13558f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:07.835592Z",
     "iopub.status.busy": "2023-05-06T22:57:07.834591Z",
     "iopub.status.idle": "2023-05-06T22:57:07.848602Z",
     "shell.execute_reply": "2023-05-06T22:57:07.847601Z",
     "shell.execute_reply.started": "2023-05-06T22:57:07.835592Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all possible processors\n",
    "\n",
    "def print_possible_processors () :\n",
    "\t\"\"\"\n",
    "\tDoc\n",
    "\t\"\"\"\n",
    "\n",
    "\tfor k, v in PROCESSORS.items() :\n",
    "\t\tprint('{:12s} : {:>24s}'.format(k, v.__name__))\n",
    "\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb67f6e-c557-4e7b-8fc0-a671a6f0c512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:07.850104Z",
     "iopub.status.busy": "2023-05-06T22:57:07.849604Z",
     "iopub.status.idle": "2023-05-06T22:57:07.863617Z",
     "shell.execute_reply": "2023-05-06T22:57:07.863114Z",
     "shell.execute_reply.started": "2023-05-06T22:57:07.850104Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display all possible output modes\n",
    "\n",
    "def print_possible_output_modes () :\n",
    "\t\"\"\"\n",
    "\tDoc\n",
    "\t\"\"\"\n",
    "\n",
    "\tfor k, v in MODES.items() :\n",
    "\t\tprint('{:12s} : {:>14s}'.format(k, v))\n",
    "\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc83f8-24b3-441a-be15-4d0076f4ebd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b0f127-8646-4e6e-96e3-391c966c2fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:07.868119Z",
     "iopub.status.busy": "2023-05-06T22:57:07.867119Z",
     "iopub.status.idle": "2023-05-06T22:57:07.895142Z",
     "shell.execute_reply": "2023-05-06T22:57:07.894142Z",
     "shell.execute_reply.started": "2023-05-06T22:57:07.868119Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main method\n",
    "\n",
    "def main () :\n",
    "\t\"\"\"\n",
    "\tDoc\n",
    "\t\"\"\"\n",
    "\n",
    "\tparser  =  argparse.ArgumentParser()\n",
    "\n",
    "\t# Required parameters\n",
    "\tparser.add_argument('--data_dir',           default = None, type = str, required = True, help = 'The input data dir. Should contain the .tsv files (or other data files) for the task.')\n",
    "\tparser.add_argument('--model_type',         default = None, type = str, required = True, help = 'Model type selected in the list: ' + ', '.join(MODELS.keys()))\n",
    "\tparser.add_argument('--model_name_or_path', default = None, type = str, required = True, help = 'Path to pre-trained model or shortcut name selected in the list: ' + ', '.join(PRETRAINED_MODELS))\n",
    "\tparser.add_argument('--task_name',          default = None, type = str, required = True, help = 'The name of the task to train selected in the list: ' + ', '.join(PROCESSORS.keys()))\n",
    "\tparser.add_argument('--output_dir',         default = None, type = str, required = True, help = 'The output directory where the model predictions and checkpoints will be written.')\n",
    "\n",
    "\t# Other parameters\n",
    "\tparser.add_argument('--n_process',                    default = 2,      type = int,   help = 'The number of processes used for data process')\n",
    "\tparser.add_argument('--visualize_data_dir',           default = None,   type = str,   help = 'The input data dir. Should contain the .tsv files for the task.')\n",
    "\tparser.add_argument('--result_dir',                   default = None,   type = str,   help = 'The directory where the dna690 and mouse will save results.')\n",
    "\tparser.add_argument('--config_name',                  default = '',     type = str,   help = 'Pretrained config name or path if not the same as model_name')\n",
    "\tparser.add_argument('--tokenizer_name',               default = '',     type = str,   help = 'Pretrained tokenizer name or path if not the same as model_name')\n",
    "\tparser.add_argument('--cache_dir',                    default = '',     type = str,   help = 'Where do you want to store the pre-trained models downloaded from s3')\n",
    "\tparser.add_argument('--predict_dir',                  default = None,   type = str,   help = 'The output directory of predicted result. (when do_predict)')\n",
    "\tparser.add_argument('--max_seq_length',               default = 128,    type = int,   help = 'The maximum total input sequence length after tokenization.')\n",
    "\tparser.add_argument('--per_gpu_train_batch_size',     default = 8,      type = int,   help = 'Batch size per GPU/CPU for training.')\n",
    "\tparser.add_argument('--per_gpu_eval_batch_size',      default = 8,      type = int,   help = 'Batch size per GPU/CPU for evaluation.')\n",
    "\tparser.add_argument('--per_gpu_pred_batch_size',      default = 8,      type = int,   help = 'Batch size per GPU/CPU for prediction.')\n",
    "\tparser.add_argument('--early_stop',                   default = 0,      type = int,   help = 'set this to a positive integet if you want to perfrom early stop.')\n",
    "\tparser.add_argument('--predict_scan_size',            default = 1,      type = int,   help = 'Number of updates steps to accumulate before performing a backward/update pass.')\n",
    "\tparser.add_argument('--gradient_accumulation_steps',  default = 1,      type = int,   help = 'Number of updates steps to accumulate before performing a backward/update pass.')\n",
    "\tparser.add_argument('--learning_rate',                default = 5e-5,   type = float, help = 'The initial learning rate for Adam.')\n",
    "\tparser.add_argument('--weight_decay',                 default = 0.0,    type = float, help = 'Weight decay if we apply some.')\n",
    "\tparser.add_argument('--adam_epsilon',                 default = 1e-8,   type = float, help = 'Epsilon for Adam optimizer.')\n",
    "\tparser.add_argument('--beta1',                        default = 0.9,    type = float, help = 'Beta1 for Adam optimizer.')\n",
    "\tparser.add_argument('--beta2',                        default = 0.999,  type = float, help = 'Beta2 for Adam optimizer.')\n",
    "\tparser.add_argument('--max_grad_norm',                default = 1.0,    type = float, help = 'Max gradient norm.')\n",
    "\tparser.add_argument('--attention_probs_dropout_prob', default = 0.1,    type = float, help = 'Dropout rate of attention.')\n",
    "\tparser.add_argument('--hidden_dropout_prob',          default = 0.1,    type = float, help = 'Dropout rate of intermidiete layer.')\n",
    "\tparser.add_argument('--rnn_dropout',                  default = 0.0,    type = float, help = 'Dropout rate of intermidiete layer.')\n",
    "\tparser.add_argument('--rnn',                          default = 'lstm', type = str,   help = 'What kind of RNN to use')\n",
    "\tparser.add_argument('--num_rnn_layer',                default = 2,      type = int,   help = 'Number of rnn layers in dnalong model.')\n",
    "\tparser.add_argument('--rnn_hidden',                   default = 768,    type = int,   help = 'Number of hidden unit in a rnn layer.')\n",
    "\tparser.add_argument('--num_train_epochs',             default = 3.0,    type = float, help = 'Total number of training epochs to perform.')\n",
    "\tparser.add_argument('--max_steps',                    default = -1,     type = int,   help = 'If > 0: set total number of training steps to perform. Override num_train_epochs.')\n",
    "\tparser.add_argument('--warmup_steps',                 default = 0,      type = int,   help = 'Linear warmup over warmup_steps.')\n",
    "\tparser.add_argument('--warmup_percent',               default = 0,      type = float, help = 'Linear warmup over warmup_percent*total_steps.')\n",
    "\tparser.add_argument('--logging_steps',                default = 500,    type = int,   help = 'Log every X updates steps.')\n",
    "\tparser.add_argument('--save_steps',                   default = 500,    type = int,   help = 'Save checkpoint every X updates steps.')\n",
    "\tparser.add_argument('--save_total_limit',             default = None,   type = int,   help = 'Limit the total amount of checkpoints.')\n",
    "\tparser.add_argument('--visualize_models',             default = None,   type = int,   help = 'The model used to do visualization. If None, use 3456.')\n",
    "\tparser.add_argument('--seed',                         default = 42,     type = int,   help = 'random seed for initialization')\n",
    "\tparser.add_argument('--fp16_opt_level',               default = 'O1',   type = str,   help = 'For fp16 see details at https://nvidia.github.io/apex/amp.html')\n",
    "\tparser.add_argument('--local_rank',                   default = -1,     type = int,   help = 'For distributed training: local_rank')\n",
    "\tparser.add_argument('--server_ip',                    default = '',     type = str,   help = 'For distant debugging.')\n",
    "\tparser.add_argument('--server_port',                  default = '',     type = str,   help = 'For distant debugging.')\n",
    "\n",
    "\tparser.add_argument('--should_continue',          action = 'store_true', help = 'Whether to continue from latest checkpoint in output_dir')\n",
    "\tparser.add_argument('--do_train',                 action = 'store_true', help = 'Whether to run training.')\n",
    "\tparser.add_argument('--do_eval',                  action = 'store_true', help = 'Whether to run eval on the dev set.')\n",
    "\tparser.add_argument('--do_predict',               action = 'store_true', help = 'Whether to do prediction on the given dataset.')\n",
    "\tparser.add_argument('--do_visualize',             action = 'store_true', help = 'Whether to calculate attention score.')\n",
    "\tparser.add_argument('--visualize_train',          action = 'store_true', help = 'Whether to visualize train.tsv or dev.tsv.')\n",
    "\tparser.add_argument('--do_ensemble_pred',         action = 'store_true', help = 'Whether to do ensemble prediction with kmer 3456.')\n",
    "\tparser.add_argument('--evaluate_during_training', action = 'store_true', help = 'Run evaluation during training at each logging step.')\n",
    "\tparser.add_argument('--do_lower_case',            action = 'store_true', help = 'Set this flag if you are using an uncased model.')\n",
    "\tparser.add_argument('--eval_all_checkpoints',     action = 'store_true', help = 'Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number')\n",
    "\tparser.add_argument('--no_cuda',                  action = 'store_true', help = 'Avoid using CUDA when available')\n",
    "\tparser.add_argument('--overwrite_output_dir',     action = 'store_true', help = 'Overwrite the content of the output directory')\n",
    "\tparser.add_argument('--overwrite_cache',          action = 'store_true', help = 'Overwrite the cached training and evaluation sets')\n",
    "\tparser.add_argument('--fp16',                     action = 'store_true', help = 'Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit')\n",
    "\n",
    "\t# Added parameters\n",
    "\tparser.add_argument('--optimizer',     default = 'adamw', type = str)\n",
    "\tparser.add_argument('--freeze_layers', default = 12,      type = int)\n",
    "\tparser.add_argument('--num_features',  default = 72,      type = int)\n",
    "\n",
    "\targs   = parser.parse_args()\n",
    "\tlogger = logging.getLogger(__name__)\n",
    "\n",
    "\t#\n",
    "\t# Features\n",
    "\t#\n",
    "\n",
    "\tuse_features = args.num_features > 0\n",
    "\tnum_features = args.num_features\n",
    "\n",
    "\t#\n",
    "\t# Init arguments\n",
    "\t#\n",
    "\n",
    "\targs = bert_init_args(\n",
    "\t\targs   = args,\n",
    "\t\tlogger = logger\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Init classes\n",
    "\t#\n",
    "\n",
    "\toutput = bert_init_classes(\n",
    "\t\targs         = args,\n",
    "\t\tlogger       = logger,\n",
    "\t\tuse_features = use_features,\n",
    "\t\tnum_features = num_features\n",
    "\t)\n",
    "\n",
    "\tmodel         = output['model']\n",
    "\ttokenizer     = output['tokenizer']\n",
    "\tconfig        = output['config']\n",
    "\tmodel_cls     = output['model_cls']\n",
    "\ttokenizer_cls = output['tokenizer_cls']\n",
    "\tconfig_cls    = output['config_cls']\n",
    "\tnum_labels    = output['num_labels']\n",
    "\n",
    "\t#\n",
    "\t# Save args\n",
    "\t#\n",
    "\n",
    "\tos.makedirs(args.output_dir, exist_ok = True)\n",
    "\n",
    "\twith open(os.path.join(args.output_dir, 'args.json'), mode = 'w') as handle :\n",
    "\t\tjson.dump(\n",
    "\t\t\tvars(args),\n",
    "\t\t\thandle,\n",
    "\t\t\tindent     = 4,\n",
    "\t\t\tseparators = (',', ' : '),\n",
    "\t\t\tsort_keys  = True,\n",
    "\t\t\tdefault    = lambda o : '<not serializable>'\n",
    "\t\t)\n",
    "\n",
    "\t#\n",
    "\t# Training\n",
    "\t#\n",
    "\n",
    "\tbert_train(\n",
    "\t\targs          = args,\n",
    "\t\tmodel         = model,\n",
    "\t\ttokenizer     = tokenizer,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Evaluation\n",
    "\t#\n",
    "\n",
    "\tbert_evaluate(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Prediction\n",
    "\t#\n",
    "\n",
    "\tbert_predict(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Visualize\n",
    "\t#\n",
    "\n",
    "\tbert_visualize(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tconfig_cls    = config_cls,\n",
    "\t\tnum_labels    = num_labels,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Ensemble\n",
    "\t#\n",
    "\n",
    "\tbert_ensamble(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tconfig_cls    = config_cls,\n",
    "\t\tnum_labels    = num_labels,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16001e-b1d9-4a75-85e4-e554e430d25b",
   "metadata": {},
   "source": [
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ec89ea-2b49-412b-bca8-632a7540a520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:07.896644Z",
     "iopub.status.busy": "2023-05-06T22:57:07.896143Z",
     "iopub.status.idle": "2023-05-06T22:57:07.910657Z",
     "shell.execute_reply": "2023-05-06T22:57:07.909656Z",
     "shell.execute_reply.started": "2023-05-06T22:57:07.896644Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing RegressionProcessor vs DnaPromProcessor vs StsbProcessor\n",
    "\n",
    "def test_processor () :\n",
    "\t\"\"\"\n",
    "\tDoc\n",
    "\t\"\"\"\n",
    "\n",
    "\tfrom transformers.data.processors.glue  import DnaPromProcessor\n",
    "\tfrom source.python.bert.bert_processors import RegressionProcessor\n",
    "\n",
    "\tpath = os.path.join(ROOT, 'source', 'python', 'bert', 'dnabert', 'examples', 'sample_data', 'ft', '6')\n",
    "\n",
    "\tfor processor in [DnaPromProcessor, RegressionProcessor] :\n",
    "\t\tname     = processor.__name__\n",
    "\t\texamples = processor().get_train_examples(path)\n",
    "\n",
    "\t\tprint()\n",
    "\t\tprint(name)\n",
    "\t\tprint('GUID  : {}'.format(examples[0].guid))\n",
    "\t\tprint('Text  : {} ... {}'.format(examples[0].text_a[:30], examples[0].text_a[-30:]))\n",
    "\t\tprint('Label : {}'.format(examples[0].label))\n",
    "\n",
    "\t\tif name == 'RegressionProcessor' :\n",
    "\t\t\tprint('Feats : {}'.format(examples[0].feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3df0f1-69e1-4419-83e4-cfcf681b756c",
   "metadata": {},
   "source": [
    "# 4. Launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5482b9ad-013f-41df-ac48-63d2ff5a32ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:57:07.912157Z",
     "iopub.status.busy": "2023-05-06T22:57:07.911658Z",
     "iopub.status.idle": "2023-05-06T22:57:08.763890Z",
     "shell.execute_reply": "2023-05-06T22:57:08.762889Z",
     "shell.execute_reply.started": "2023-05-06T22:57:07.912157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as .ipynb\n",
      "dna          :       BertConfig        BertForSequenceClassification         DNATokenizer\n",
      "dnalong      :       BertConfig    BertForLongSequenceClassification         DNATokenizer\n",
      "dnalongcat   :       BertConfig    BertForLongSequenceClassification         DNATokenizer\n",
      "bert         :       BertConfig        BertForSequenceClassification        BertTokenizer\n",
      "xlnet        :      XLNetConfig       XLNetForSequenceClassification       XLNetTokenizer\n",
      "xlm          :        XLMConfig         XLMForSequenceClassification         XLMTokenizer\n",
      "roberta      :    RobertaConfig     RobertaForSequenceClassification     RobertaTokenizer\n",
      "distilbert   : DistilBertConfig  DistilBertForSequenceClassification  DistilBertTokenizer\n",
      "albert       :     AlbertConfig      AlbertForSequenceClassification      AlbertTokenizer\n",
      "xlmroberta   : XLMRobertaConfig  XLMRobertaForSequenceClassification  XLMRobertaTokenizer\n",
      "flaubert     :   FlaubertConfig    FlaubertForSequenceClassification    FlaubertTokenizer\n",
      "rbertfc1     :       BertConfig                    RegressionBertFC1         DNATokenizer\n",
      "rbertfc3     :       BertConfig                    RegressionBertFC3         DNATokenizer\n",
      "rbertfc3_def :       BertConfig                    RegressionBertFC3         DNATokenizer\n",
      "rbertfc3_cat :       BertConfig                 CatRegressionBertFC3         DNATokenizer\n",
      "rbertfc3_rnn :       BertConfig                 RnnRegressionBertFC3         DNATokenizer\n",
      "\n",
      "cola         :            ColaProcessor\n",
      "mnli         :            MnliProcessor\n",
      "mnli-mm      :  MnliMismatchedProcessor\n",
      "mrpc         :            MrpcProcessor\n",
      "sst-2        :            Sst2Processor\n",
      "sts-b        :            StsbProcessor\n",
      "qqp          :             QqpProcessor\n",
      "qnli         :            QnliProcessor\n",
      "rte          :             RteProcessor\n",
      "wnli         :            WnliProcessor\n",
      "dnaprom      :         DnaPromProcessor\n",
      "dna690       :         DnaPromProcessor\n",
      "dnapair      :         DnaPairProcessor\n",
      "dnasplice    :       DnaSpliceProcessor\n",
      "regression   :      RegressionProcessor\n",
      "\n",
      "cola         : classification\n",
      "mnli         : classification\n",
      "mnli-mm      : classification\n",
      "mrpc         : classification\n",
      "sst-2        : classification\n",
      "sts-b        :     regression\n",
      "qqp          : classification\n",
      "qnli         : classification\n",
      "rte          : classification\n",
      "wnli         : classification\n",
      "dnaprom      : classification\n",
      "dna690       : classification\n",
      "dnapair      : classification\n",
      "dnasplice    : classification\n",
      "regression   :     regression\n",
      "\n",
      "\n",
      "DnaPromProcessor\n",
      "GUID  : train-1\n",
      "Text  : CACAGC ACAGCC CAGCCA AGCCAG GC ... CC GTGCCA TGCCAC GCCACA CCACAC\n",
      "Label : 0\n",
      "\n",
      "RegressionProcessor\n",
      "GUID  : train-1\n",
      "Text  : CACAGC ACAGCC CAGCCA AGCCAG GC ... CC GTGCCA TGCCAC GCCACA CCACAC\n",
      "Label : 0.0\n",
      "Feats : None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' and 'get_ipython' in dir() :\n",
    "\tprint('Running as .ipynb')\n",
    "\n",
    "\tprint_possible_models()\n",
    "\tprint_possible_processors()\n",
    "\tprint_possible_output_modes()\n",
    "\ttest_processor()\n",
    "\n",
    "if __name__ == '__main__' and 'get_ipython' not in dir() :\n",
    "\tprint('Running as .py')\n",
    "\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
