{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f08f55-17e9-4f66-b952-60801d8cc696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:25.001983Z",
     "iopub.status.busy": "2023-03-23T10:15:25.001983Z",
     "iopub.status.idle": "2023-03-23T10:15:26.135956Z",
     "shell.execute_reply": "2023-03-23T10:15:26.135456Z",
     "shell.execute_reply.started": "2023-03-23T10:15:25.001983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import numpy\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84acd8e-25d9-4238-b0e5-9273e7ec66a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:26.137958Z",
     "iopub.status.busy": "2023-03-23T10:15:26.137958Z",
     "iopub.status.idle": "2023-03-23T10:15:26.151470Z",
     "shell.execute_reply": "2023-03-23T10:15:26.150968Z",
     "shell.execute_reply.started": "2023-03-23T10:15:26.137958Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure source path\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "while not ROOT.endswith('upolanc-thesis') :\n",
    "\tROOT = os.path.abspath(os.path.join(ROOT, os.pardir))\n",
    "\n",
    "\tif len(ROOT) < len('upolanc-thesis') :\n",
    "\t\tif   platform.system() == 'Linux' :\n",
    "\t\t\tROOT = '/d/hpc/home/up4472/workspace/upolanc-thesis'\n",
    "\t\telif platform.system() == 'Windows' :\n",
    "\t\t\tROOT = 'C:\\\\Developer\\\\Workspace\\\\PyCharm\\\\Projects\\\\upolanc-thesis'\n",
    "\t\telse :\n",
    "\t\t\traise ValueError()\n",
    "\n",
    "\t\tprint(f'Warning : could not find correct directory, using default : {ROOT}')\n",
    "\t\tbreak\n",
    "\n",
    "if ROOT not in sys.path :\n",
    "\tsys.path.append(ROOT)\n",
    "\n",
    "os.chdir(ROOT)\n",
    "\n",
    "sys.path.append(os.path.join(ROOT, 'source', 'python', 'bert', 'dnabert', 'src'))\n",
    "sys.path.append(os.path.join(ROOT, 'source', 'python', 'bert', 'dnabert', 'src', 'transformers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92d31bc-301c-46b7-ab48-965a462cc521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:26.152470Z",
     "iopub.status.busy": "2023-03-23T10:15:26.152470Z",
     "iopub.status.idle": "2023-03-23T10:15:27.563181Z",
     "shell.execute_reply": "2023-03-23T10:15:27.562680Z",
     "shell.execute_reply.started": "2023-03-23T10:15:26.152470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "from source.python.bert.bert_constants import MODELS\n",
    "from source.python.bert.bert_constants import MODES\n",
    "from source.python.bert.bert_constants import PRETRAINED_MODELS\n",
    "from source.python.bert.bert_constants import PROCESSORS\n",
    "\n",
    "from source.python.bert.bert_main      import bert_init_args\n",
    "from source.python.bert.bert_main      import bert_init_classes\n",
    "from source.python.bert.bert_main      import bert_train\n",
    "from source.python.bert.bert_main      import bert_evaluate\n",
    "from source.python.bert.bert_main      import bert_predict\n",
    "from source.python.bert.bert_main      import bert_visualize\n",
    "from source.python.bert.bert_main      import bert_ensamble\n",
    "from source.python                     import runtime\n",
    "\n",
    "runtime.set_numpy_format()\n",
    "runtime.set_pandas_format()\n",
    "runtime.set_plot_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430bb6b-342c-49ed-ba1e-c8801389487b",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04602cda-6f5d-4d6b-8ad3-ae2c7b67348f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:27.564182Z",
     "iopub.status.busy": "2023-03-23T10:15:27.563681Z",
     "iopub.status.idle": "2023-03-23T10:15:27.578695Z",
     "shell.execute_reply": "2023-03-23T10:15:27.578194Z",
     "shell.execute_reply.started": "2023-03-23T10:15:27.564182Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna          :       BertConfig        BertForSequenceClassification         DNATokenizer\n",
      "dnalong      :       BertConfig    BertForLongSequenceClassification         DNATokenizer\n",
      "dnalongcat   :       BertConfig    BertForLongSequenceClassification         DNATokenizer\n",
      "bert         :       BertConfig        BertForSequenceClassification        BertTokenizer\n",
      "xlnet        :      XLNetConfig       XLNetForSequenceClassification       XLNetTokenizer\n",
      "xlm          :        XLMConfig         XLMForSequenceClassification         XLMTokenizer\n",
      "roberta      :    RobertaConfig     RobertaForSequenceClassification     RobertaTokenizer\n",
      "distilbert   : DistilBertConfig  DistilBertForSequenceClassification  DistilBertTokenizer\n",
      "albert       :     AlbertConfig      AlbertForSequenceClassification      AlbertTokenizer\n",
      "xlmroberta   : XLMRobertaConfig  XLMRobertaForSequenceClassification  XLMRobertaTokenizer\n",
      "flaubert     :   FlaubertConfig    FlaubertForSequenceClassification    FlaubertTokenizer\n",
      "rbertfc1     :       BertConfig                    RegressionBertFC1         DNATokenizer\n",
      "rbertfc3     :       BertConfig                    RegressionBertFC3         DNATokenizer\n"
     ]
    }
   ],
   "source": [
    "# Display all possible models\n",
    "\n",
    "for k, v in MODELS.items() :\n",
    "\tprint('{:12s} : {:>16s} {:>36s} {:>20s}'.format(k, v[0].__name__, v[1].__name__, v[2].__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e94974-c96b-47c2-8329-3024e13558f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:27.579695Z",
     "iopub.status.busy": "2023-03-23T10:15:27.579695Z",
     "iopub.status.idle": "2023-03-23T10:15:27.594208Z",
     "shell.execute_reply": "2023-03-23T10:15:27.593707Z",
     "shell.execute_reply.started": "2023-03-23T10:15:27.579695Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola         :            ColaProcessor\n",
      "mnli         :            MnliProcessor\n",
      "mnli-mm      :  MnliMismatchedProcessor\n",
      "mrpc         :            MrpcProcessor\n",
      "sst-2        :            Sst2Processor\n",
      "sts-b        :            StsbProcessor\n",
      "qqp          :             QqpProcessor\n",
      "qnli         :            QnliProcessor\n",
      "rte          :             RteProcessor\n",
      "wnli         :            WnliProcessor\n",
      "dnaprom      :         DnaPromProcessor\n",
      "dna690       :         DnaPromProcessor\n",
      "dnapair      :         DnaPairProcessor\n",
      "dnasplice    :       DnaSpliceProcessor\n",
      "regression   :      RegressionProcessor\n"
     ]
    }
   ],
   "source": [
    "# Display all possible processors\n",
    "\n",
    "for k, v in PROCESSORS.items() :\n",
    "\tprint('{:12s} : {:>24s}'.format(k, v.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb67f6e-c557-4e7b-8fc0-a671a6f0c512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:27.595209Z",
     "iopub.status.busy": "2023-03-23T10:15:27.595209Z",
     "iopub.status.idle": "2023-03-23T10:15:27.609721Z",
     "shell.execute_reply": "2023-03-23T10:15:27.609220Z",
     "shell.execute_reply.started": "2023-03-23T10:15:27.595209Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cola         : classification\n",
      "mnli         : classification\n",
      "mnli-mm      : classification\n",
      "mrpc         : classification\n",
      "sst-2        : classification\n",
      "sts-b        :     regression\n",
      "qqp          : classification\n",
      "qnli         : classification\n",
      "rte          : classification\n",
      "wnli         : classification\n",
      "dnaprom      : classification\n",
      "dna690       : classification\n",
      "dnapair      : classification\n",
      "dnasplice    : classification\n",
      "regression   :     regression\n"
     ]
    }
   ],
   "source": [
    "# Display all possible output modes\n",
    "\n",
    "for k, v in MODES.items() :\n",
    "\tprint('{:12s} : {:>14s}'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc83f8-24b3-441a-be15-4d0076f4ebd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b0f127-8646-4e6e-96e3-391c966c2fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:27.612223Z",
     "iopub.status.busy": "2023-03-23T10:15:27.611723Z",
     "iopub.status.idle": "2023-03-23T10:15:27.640748Z",
     "shell.execute_reply": "2023-03-23T10:15:27.640247Z",
     "shell.execute_reply.started": "2023-03-23T10:15:27.611723Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main method\n",
    "\n",
    "def main () :\n",
    "\t\"\"\"\n",
    "\tDoc\n",
    "\t\"\"\"\n",
    "\n",
    "\tparser  =  argparse.ArgumentParser()\n",
    "\n",
    "\t# Required parameters\n",
    "\tparser.add_argument('--data_dir',           default = None, type = str, required = True, help = 'The input data dir. Should contain the .tsv files (or other data files) for the task.')\n",
    "\tparser.add_argument('--model_type',         default = None, type = str, required = True, help = 'Model type selected in the list: ' + ', '.join(MODELS.keys()))\n",
    "\tparser.add_argument('--model_name_or_path', default = None, type = str, required = True, help = 'Path to pre-trained model or shortcut name selected in the list: ' + ', '.join(PRETRAINED_MODELS))\n",
    "\tparser.add_argument('--task_name',          default = None, type = str, required = True, help = 'The name of the task to train selected in the list: ' + ', '.join(PROCESSORS.keys()))\n",
    "\tparser.add_argument('--output_dir',         default = None, type = str, required = True, help = 'The output directory where the model predictions and checkpoints will be written.')\n",
    "\n",
    "\t# Other parameters\n",
    "\tparser.add_argument('--n_process',                    default = 2,      type = int,   help = 'The number of processes used for data process')\n",
    "\tparser.add_argument('--visualize_data_dir',           default = None,   type = str,   help = 'The input data dir. Should contain the .tsv files for the task.')\n",
    "\tparser.add_argument('--result_dir',                   default = None,   type = str,   help = 'The directory where the dna690 and mouse will save results.')\n",
    "\tparser.add_argument('--config_name',                  default = '',     type = str,   help = 'Pretrained config name or path if not the same as model_name')\n",
    "\tparser.add_argument('--tokenizer_name',               default = '',     type = str,   help = 'Pretrained tokenizer name or path if not the same as model_name')\n",
    "\tparser.add_argument('--cache_dir',                    default = '',     type = str,   help = 'Where do you want to store the pre-trained models downloaded from s3')\n",
    "\tparser.add_argument('--predict_dir',                  default = None,   type = str,   help = 'The output directory of predicted result. (when do_predict)')\n",
    "\tparser.add_argument('--max_seq_length',               default = 128,    type = int,   help = 'The maximum total input sequence length after tokenization.')\n",
    "\tparser.add_argument('--per_gpu_train_batch_size',     default = 8,      type = int,   help = 'Batch size per GPU/CPU for training.')\n",
    "\tparser.add_argument('--per_gpu_eval_batch_size',      default = 8,      type = int,   help = 'Batch size per GPU/CPU for evaluation.')\n",
    "\tparser.add_argument('--per_gpu_pred_batch_size',      default = 8,      type = int,   help = 'Batch size per GPU/CPU for prediction.')\n",
    "\tparser.add_argument('--early_stop',                   default = 0,      type = int,   help = 'set this to a positive integet if you want to perfrom early stop.')\n",
    "\tparser.add_argument('--predict_scan_size',            default = 1,      type = int,   help = 'Number of updates steps to accumulate before performing a backward/update pass.')\n",
    "\tparser.add_argument('--gradient_accumulation_steps',  default = 1,      type = int,   help = 'Number of updates steps to accumulate before performing a backward/update pass.')\n",
    "\tparser.add_argument('--learning_rate',                default = 5e-5,   type = float, help = 'The initial learning rate for Adam.')\n",
    "\tparser.add_argument('--weight_decay',                 default = 0.0,    type = float, help = 'Weight decay if we apply some.')\n",
    "\tparser.add_argument('--adam_epsilon',                 default = 1e-8,   type = float, help = 'Epsilon for Adam optimizer.')\n",
    "\tparser.add_argument('--beta1',                        default = 0.9,    type = float, help = 'Beta1 for Adam optimizer.')\n",
    "\tparser.add_argument('--beta2',                        default = 0.999,  type = float, help = 'Beta2 for Adam optimizer.')\n",
    "\tparser.add_argument('--max_grad_norm',                default = 1.0,    type = float, help = 'Max gradient norm.')\n",
    "\tparser.add_argument('--attention_probs_dropout_prob', default = 0.1,    type = float, help = 'Dropout rate of attention.')\n",
    "\tparser.add_argument('--hidden_dropout_prob',          default = 0.1,    type = float, help = 'Dropout rate of intermidiete layer.')\n",
    "\tparser.add_argument('--rnn_dropout',                  default = 0.0,    type = float, help = 'Dropout rate of intermidiete layer.')\n",
    "\tparser.add_argument('--rnn',                          default = 'lstm', type = str,   help = 'What kind of RNN to use')\n",
    "\tparser.add_argument('--num_rnn_layer',                default = 2,      type = int,   help = 'Number of rnn layers in dnalong model.')\n",
    "\tparser.add_argument('--rnn_hidden',                   default = 768,    type = int,   help = 'Number of hidden unit in a rnn layer.')\n",
    "\tparser.add_argument('--num_train_epochs',             default = 3.0,    type = float, help = 'Total number of training epochs to perform.')\n",
    "\tparser.add_argument('--max_steps',                    default = -1,     type = int,   help = 'If > 0: set total number of training steps to perform. Override num_train_epochs.')\n",
    "\tparser.add_argument('--warmup_steps',                 default = 0,      type = int,   help = 'Linear warmup over warmup_steps.')\n",
    "\tparser.add_argument('--warmup_percent',               default = 0,      type = float, help = 'Linear warmup over warmup_percent*total_steps.')\n",
    "\tparser.add_argument('--logging_steps',                default = 500,    type = int,   help = 'Log every X updates steps.')\n",
    "\tparser.add_argument('--save_steps',                   default = 500,    type = int,   help = 'Save checkpoint every X updates steps.')\n",
    "\tparser.add_argument('--save_total_limit',             default = None,   type = int,   help = 'Limit the total amount of checkpoints.')\n",
    "\tparser.add_argument('--visualize_models',             default = None,   type = int,   help = 'The model used to do visualization. If None, use 3456.')\n",
    "\tparser.add_argument('--seed',                         default = 42,     type = int,   help = 'random seed for initialization')\n",
    "\tparser.add_argument('--fp16_opt_level',               default = 'O1',   type = str,   help = 'For fp16 see details at https://nvidia.github.io/apex/amp.html')\n",
    "\tparser.add_argument('--local_rank',                   default = -1,     type = int,   help = 'For distributed training: local_rank')\n",
    "\tparser.add_argument('--server_ip',                    default = '',     type = str,   help = 'For distant debugging.')\n",
    "\tparser.add_argument('--server_port',                  default = '',     type = str,   help = 'For distant debugging.')\n",
    "\n",
    "\tparser.add_argument('--should_continue',          action = 'store_true', help = 'Whether to continue from latest checkpoint in output_dir')\n",
    "\tparser.add_argument('--do_train',                 action = 'store_true', help = 'Whether to run training.')\n",
    "\tparser.add_argument('--do_eval',                  action = 'store_true', help = 'Whether to run eval on the dev set.')\n",
    "\tparser.add_argument('--do_predict',               action = 'store_true', help = 'Whether to do prediction on the given dataset.')\n",
    "\tparser.add_argument('--do_visualize',             action = 'store_true', help = 'Whether to calculate attention score.')\n",
    "\tparser.add_argument('--visualize_train',          action = 'store_true', help = 'Whether to visualize train.tsv or dev.tsv.')\n",
    "\tparser.add_argument('--do_ensemble_pred',         action = 'store_true', help = 'Whether to do ensemble prediction with kmer 3456.')\n",
    "\tparser.add_argument('--evaluate_during_training', action = 'store_true', help = 'Run evaluation during training at each logging step.')\n",
    "\tparser.add_argument('--do_lower_case',            action = 'store_true', help = 'Set this flag if you are using an uncased model.')\n",
    "\tparser.add_argument('--eval_all_checkpoints',     action = 'store_true', help = 'Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number')\n",
    "\tparser.add_argument('--no_cuda',                  action = 'store_true', help = 'Avoid using CUDA when available')\n",
    "\tparser.add_argument('--overwrite_output_dir',     action = 'store_true', help = 'Overwrite the content of the output directory')\n",
    "\tparser.add_argument('--overwrite_cache',          action = 'store_true', help = 'Overwrite the cached training and evaluation sets')\n",
    "\tparser.add_argument('--fp16',                     action = 'store_true', help = 'Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit')\n",
    "\n",
    "\targs   = parser.parse_args()\n",
    "\tlogger = logging.getLogger(__name__)\n",
    "\n",
    "\t#\n",
    "\t# Features (extra :: need to be tested)\n",
    "\t#\n",
    "\n",
    "\tuse_features = False\n",
    "\tnum_features = 72\n",
    "\n",
    "\t#\n",
    "\t# Init arguments\n",
    "\t#\n",
    "\n",
    "\targs = bert_init_args(\n",
    "\t\targs   = args,\n",
    "\t\tlogger = logger\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Init classes\n",
    "\t#\n",
    "\n",
    "\toutput = bert_init_classes(\n",
    "\t\targs         = args,\n",
    "\t\tlogger       = logger,\n",
    "\t\tuse_features = use_features,\n",
    "\t\tnum_features = num_features\n",
    "\t)\n",
    "\n",
    "\tmodel         = output['model']\n",
    "\ttokenizer     = output['tokenizer']\n",
    "\tconfig        = output['config']\n",
    "\tmodel_cls     = output['model_cls']\n",
    "\ttokenizer_cls = output['tokenizer_cls']\n",
    "\tconfig_cls    = output['config_cls']\n",
    "\tnum_labels    = output['num_labels']\n",
    "\n",
    "\t#\n",
    "\t# Training\n",
    "\t#\n",
    "\n",
    "\tbert_train(\n",
    "\t\targs          = args,\n",
    "\t\tmodel         = model,\n",
    "\t\ttokenizer     = tokenizer,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Evaluation\n",
    "\t#\n",
    "\n",
    "\tbert_evaluate(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Prediction\n",
    "\t#\n",
    "\n",
    "\tbert_predict(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Visualize\n",
    "\t#\n",
    "\n",
    "\tbert_visualize(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tconfig_cls    = config_cls,\n",
    "\t\tnum_labels    = num_labels,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)\n",
    "\n",
    "\t#\n",
    "\t# Ensemble\n",
    "\t#\n",
    "\n",
    "\tbert_ensamble(\n",
    "\t\targs          = args,\n",
    "\t\tmodel_cls     = model_cls,\n",
    "\t\ttokenizer_cls = tokenizer_cls,\n",
    "\t\tconfig_cls    = config_cls,\n",
    "\t\tnum_labels    = num_labels,\n",
    "\t\tlogger        = logger,\n",
    "\t\tuse_features  = use_features\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a16001e-b1d9-4a75-85e4-e554e430d25b",
   "metadata": {},
   "source": [
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ec89ea-2b49-412b-bca8-632a7540a520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:27.641748Z",
     "iopub.status.busy": "2023-03-23T10:15:27.641247Z",
     "iopub.status.idle": "2023-03-23T10:15:27.656260Z",
     "shell.execute_reply": "2023-03-23T10:15:27.655760Z",
     "shell.execute_reply.started": "2023-03-23T10:15:27.641748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing RegressionProcessor vs DnaPromProcessor vs StsbProcessor\n",
    "\n",
    "def test_processor () :\n",
    "\t\"\"\"\n",
    "\tDoc\n",
    "\t\"\"\"\n",
    "\n",
    "\tfrom transformers.data.processors.glue  import DnaPromProcessor\n",
    "\tfrom source.python.bert.bert_processors import RegressionProcessor\n",
    "\n",
    "\tpath = os.path.join(ROOT, 'source', 'python', 'bert', 'dnabert', 'examples', 'sample_data', 'ft', '6')\n",
    "\n",
    "\tfor processor in [DnaPromProcessor, RegressionProcessor] :\n",
    "\t\tname     = processor.__name__\n",
    "\t\texamples = processor().get_train_examples(path)\n",
    "\n",
    "\t\tprint()\n",
    "\t\tprint(name)\n",
    "\t\tprint('GUID  : {}'.format(examples[0].guid))\n",
    "\t\tprint('Text  : {} ... {}'.format(examples[0].text_a[:30], examples[0].text_a[-30:]))\n",
    "\t\tprint('Label : {}'.format(examples[0].label))\n",
    "\n",
    "\t\tif name == 'RegressionProcessor' :\n",
    "\t\t\tprint('Feats : {}'.format(examples[0].feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3df0f1-69e1-4419-83e4-cfcf681b756c",
   "metadata": {},
   "source": [
    "# 4. Launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5482b9ad-013f-41df-ac48-63d2ff5a32ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T10:15:27.657261Z",
     "iopub.status.busy": "2023-03-23T10:15:27.656760Z",
     "iopub.status.idle": "2023-03-23T10:15:28.354360Z",
     "shell.execute_reply": "2023-03-23T10:15:28.353859Z",
     "shell.execute_reply.started": "2023-03-23T10:15:27.657261Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as .ipynb\n",
      "\n",
      "DnaPromProcessor\n",
      "GUID  : train-1\n",
      "Text  : CACAGC ACAGCC CAGCCA AGCCAG GC ... CC GTGCCA TGCCAC GCCACA CCACAC\n",
      "Label : 0\n",
      "\n",
      "RegressionProcessor\n",
      "GUID  : train-1\n",
      "Text  : CACAGC ACAGCC CAGCCA AGCCAG GC ... CC GTGCCA TGCCAC GCCACA CCACAC\n",
      "Label : 0\n",
      "Feats : None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' and 'get_ipython' in dir() :\n",
    "\tprint('Running as .ipynb')\n",
    "\n",
    "\ttest_processor()\n",
    "\n",
    "if __name__ == '__main__' and 'get_ipython' not in dir() :\n",
    "\tprint('Running as .py')\n",
    "\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
