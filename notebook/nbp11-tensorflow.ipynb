{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e7a20-55fe-4ced-a4cd-74961c61b7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ff36d-f656-48fd-8d18-f7580df4df2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure source path\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "while not ROOT.endswith('upolanc-thesis') :\n",
    "\tROOT = os.path.abspath(os.path.join(ROOT, os.pardir))\n",
    "\n",
    "\tif len(ROOT) < len('upolanc-thesis') :\n",
    "\t\tif   platform.system() == 'Linux'   : ROOT = '/d/hpc/projects/FRI/up4472/upolanc-thesis'\n",
    "\t\telif platform.system() == 'Windows' : ROOT = 'C:\\\\Developer\\\\Workspace\\\\PyCharm\\\\Projects\\\\upolanc-thesis'\n",
    "\t\telse : raise ValueError()\n",
    "\n",
    "\t\tprint(f'Warning : could not find correct directory, using default : {ROOT}')\n",
    "\t\tprint()\n",
    "\n",
    "\t\tbreak\n",
    "\n",
    "if ROOT not in sys.path :\n",
    "\tsys.path.append(ROOT)\n",
    "\n",
    "os.chdir(ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1d91b-c0c8-4523-ab7a-12b59917c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "from source.python                       import runtime\n",
    "from source.python.dataset               import dataset_split\n",
    "from source.python.dataset               import dataset_utils\n",
    "from source.python.dataset.dataset_split import generate_group_shuffle_split\n",
    "from source.python.dataset.dataset_split import generate_random_shuffle_split\n",
    "from source.python.dataset.dataset_split import generate_stratified_shuffle_split\n",
    "from source.python.io                    import loader\n",
    "from source.python.io                    import writer\n",
    "\n",
    "runtime.set_numpy_format()\n",
    "runtime.set_pandas_format()\n",
    "runtime.set_plot_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19865e19-7f16-433c-ba73-e4e42a0ad410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System and device\n",
    "\n",
    "DEVICE = runtime.get_device(only_cpu = False)\n",
    "SYSTEM = runtime.get_system_info()\n",
    "\n",
    "for key, value in SYSTEM.items() :\n",
    "\tprint('{:25s} : {}'.format(key, value))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac35b8-91e7-43b0-b559-98a4804166c2",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ac4e4-a73e-4350-b751-2521152afd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define output and inputs\n",
    "\n",
    "FILTER_ID     = 2\n",
    "SUBFOLDER     = 'filter' + str(FILTER_ID)\n",
    "SEQUENCE_TYPE = 'transcript-2150'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458d86d-3398-4630-a172-4eeb864d7c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup some directory paths.\n",
    "\n",
    "CWD = ROOT\n",
    "OUT = os.path.join(CWD, 'output')\n",
    "RES = os.path.join(CWD, 'resources')\n",
    "\n",
    "OUT_DATA  = os.path.join(OUT, 'nbp11-tensorflow')\n",
    "RES_NBP04 = os.path.join(OUT, 'nbp04-feature', SUBFOLDER)\n",
    "RES_NBP05 = os.path.join(OUT, 'nbp05-target',  SUBFOLDER)\n",
    "\n",
    "shutil.rmtree(OUT_DATA, ignore_errors = True)\n",
    "\n",
    "os.makedirs(OUT_DATA, exist_ok = True)\n",
    "\n",
    "print(f'     Root Directory : {CWD}')\n",
    "print(f'   Output Directory : {OUT_DATA}')\n",
    "print(f' Resource Directory : {RES_NBP04}')\n",
    "print(f' Resource Directory : {RES_NBP05}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b36b3b-acf3-4468-b5eb-6ef7abfa4964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define sequence paths\n",
    "\n",
    "if SEQUENCE_TYPE == 'transcript-6150'    : sequence_keep = os.path.join(RES_NBP04, 'sequences-6150-keep.fasta')\n",
    "if SEQUENCE_TYPE == 'transcript-2150'    : sequence_keep = os.path.join(RES_NBP04, 'sequences-2150-keep.fasta')\n",
    "if SEQUENCE_TYPE == 'promoter-full-5000' : sequence_keep = os.path.join(RES_NBP04, 'sequences-promoter-full-keep.fasta')\n",
    "if SEQUENCE_TYPE == 'promoter-utr5-5000' : sequence_keep = os.path.join(RES_NBP04, 'sequences-promoter-utr5-keep.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a2f3a-c5d3-435c-8374-64ebaa484662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the input transcript features\n",
    "\n",
    "sequence_keep = loader.load_fasta(\n",
    "\tfilename  = sequence_keep,\n",
    "\tto_string = True\n",
    ")\n",
    "\n",
    "feature_base_keep = loader.load_npz(\n",
    "\tfilename = os.path.join(RES_NBP04, 'features-base-keep.npz')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f603e6-04a2-4504-9195-85ac9a653f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration file\n",
    "\n",
    "CONFIG = {\n",
    "\t'core/device'             : DEVICE,\n",
    "\t'core/random'             : None,\n",
    "\t'core/rootdir'            : ROOT,\n",
    "\t'core/verbose'            : True,\n",
    "\t'dataset/batch/test'      : 32,\n",
    "\t'dataset/batch/train'     : 32,\n",
    "\t'dataset/batch/valid'     : 32,\n",
    "\t'dataset/expanddim'       : None,\n",
    "\t'dataset/sequence/start'  : None,\n",
    "\t'dataset/sequence/end'    : None,\n",
    "\t'dataset/sequence/type'   : SEQUENCE_TYPE,\n",
    "\t'dataset/split/generator' : 'group',\n",
    "\t'dataset/split/test'      : 0.2,\n",
    "\t'dataset/split/valid'     : 0.2,\n",
    "\t'model/mode'              : 'regression',\n",
    "\t'model/output/explode'    : False,\n",
    "\t'model/output/filter'     : None,\n",
    "\t'model/output/heads'      : None,\n",
    "\t'model/output/size'       : None,\n",
    "\t'model/output/target'     : 'global',\n",
    "\t'model/output/type'       : 'mean',\n",
    "}\n",
    "\n",
    "CONFIG['core/random'] = runtime.lock_random(\n",
    "\tseed     = CONFIG['core/random'],\n",
    "\tgenerate = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665d7f5-b01f-4b05-86a5-5554c1c35360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints\n",
    "\n",
    "print('Output Target : {}'.format(CONFIG['model/output/target']))\n",
    "print('Output Type   : {}'.format(CONFIG['model/output/type']))\n",
    "print('Random Seed   : {}'.format(CONFIG['core/random']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c3688-258e-4b4e-ad7c-3b2b3fe3b863",
   "metadata": {},
   "source": [
    "# 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d5d12-20ad-4d6a-b540-7da8e24f6600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "\n",
    "dataset_keep, dataframe_keep, target_value_keep, target_order_keep = dataset_utils.get_dataset(\n",
    "\tconfig    = CONFIG,\n",
    "\tsequence  = sequence_keep,\n",
    "\tfeature   = feature_base_keep,\n",
    "\tdirectory = RES_NBP05,\n",
    "\tcached    = None,\n",
    "\tstart     = None,\n",
    "\tend       = None,\n",
    "\tfilename  = 'mapping-grouped-keep.pkl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d874b9f-25c8-496b-a75f-05050d024a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset into train, valid and test\n",
    "\n",
    "if isinstance(CONFIG['dataset/split/generator'], str) :\n",
    "\tif   CONFIG['dataset/split/generator'].startswith('stratified') : generator = generate_stratified_shuffle_split\n",
    "\telif CONFIG['dataset/split/generator'].startswith('group')      : generator = generate_group_shuffle_split\n",
    "\telif CONFIG['dataset/split/generator'].startswith('random')     : generator = generate_random_shuffle_split\n",
    "\telse : raise ValueError()\n",
    "\n",
    "generator = generator(\n",
    "\tdataset     = dataset_keep,\n",
    "\tsplit_size  = {\n",
    "\t\t'test'  : CONFIG['dataset/split/test'],\n",
    "\t\t'valid' : CONFIG['dataset/split/valid']\n",
    "\t},\n",
    "\trandom_seed = CONFIG['core/random']\n",
    ")\n",
    "\n",
    "indices = next(generator)\n",
    "\n",
    "train_indices = indices[0]\n",
    "valid_indices = indices[1] if indices[1] is not None else None\n",
    "test_indices  = indices[2] if indices[2] is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2aad99-fe45-4a09-a134-39d1e4228632",
   "metadata": {},
   "source": [
    "# 3. Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2d27f-d3a7-46ef-9cc0-5cfef2a28750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select train, valud, test data\n",
    "\n",
    "train_items = [dataset_keep[index] for index in train_indices]\n",
    "\n",
    "train_keys    = numpy.array([item[0] for item in train_items], dtype = str)\n",
    "train_onehot  = numpy.array([item[1] for item in train_items], dtype = numpy.float64)\n",
    "train_onehot  = numpy.swapaxes(train_onehot, 1, 2)\n",
    "train_feature = numpy.array([item[2] for item in train_items], dtype = numpy.float64)\n",
    "train_target  = numpy.array([item[3] for item in train_items], dtype = numpy.float64)\n",
    "\n",
    "print('Training   :')\n",
    "print('Keys       : {}'.format(', '.join([str(x) for x in numpy.shape(train_keys)])))\n",
    "print('Sequences  : {}'.format(', '.join([str(x) for x in numpy.shape(train_onehot)])))\n",
    "print('Features   : {}'.format(', '.join([str(x) for x in numpy.shape(train_feature)])))\n",
    "print('Targets    : {}'.format(', '.join([str(x) for x in numpy.shape(train_target)])))\n",
    "print()\n",
    "\n",
    "valid_items = [dataset_keep[index] for index in valid_indices]\n",
    "\n",
    "valid_keys    = numpy.array([item[0] for item in valid_items], dtype = str)\n",
    "valid_onehot  = numpy.array([item[1] for item in valid_items], dtype = numpy.float64)\n",
    "valid_onehot  = numpy.swapaxes(valid_onehot, 1, 2)\n",
    "valid_feature = numpy.array([item[2] for item in valid_items], dtype = numpy.float64)\n",
    "valid_target  = numpy.array([item[3] for item in valid_items], dtype = numpy.float64)\n",
    "\n",
    "print('Validation :')\n",
    "print('Keys       : {}'.format(', '.join([str(x) for x in numpy.shape(valid_keys)])))\n",
    "print('Sequences  : {}'.format(', '.join([str(x) for x in numpy.shape(valid_onehot)])))\n",
    "print('Features   : {}'.format(', '.join([str(x) for x in numpy.shape(valid_feature)])))\n",
    "print('Targets    : {}'.format(', '.join([str(x) for x in numpy.shape(valid_target)])))\n",
    "print()\n",
    "\n",
    "test_items = [dataset_keep[index] for index in test_indices]\n",
    "\n",
    "test_keys    = numpy.array([item[0] for item in test_items], dtype = str)\n",
    "test_onehot  = numpy.array([item[1] for item in test_items], dtype = numpy.float64)\n",
    "test_onehot  = numpy.swapaxes(test_onehot, 1, 2)\n",
    "test_feature = numpy.array([item[2] for item in test_items], dtype = numpy.float64)\n",
    "test_target  = numpy.array([item[3] for item in test_items], dtype = numpy.float64)\n",
    "\n",
    "print('Testing    :')\n",
    "print('Keys       : {}'.format(', '.join([str(x) for x in numpy.shape(test_keys)])))\n",
    "print('Sequences  : {}'.format(', '.join([str(x) for x in numpy.shape(test_onehot)])))\n",
    "print('Features   : {}'.format(', '.join([str(x) for x in numpy.shape(test_feature)])))\n",
    "print('Targets    : {}'.format(', '.join([str(x) for x in numpy.shape(test_target)])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b300e2fa-0755-4abc-a3f7-27458b060d68",
   "metadata": {},
   "source": [
    "# 4. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa5152-3c7e-4fae-b7fd-3db8ff8caf57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "\n",
    "numpy.savez(os.path.join(OUT_DATA, 'data.npz'), train_onehot, test_onehot, train_feature, test_feature, train_target, test_target)\n",
    "numpy.savez(os.path.join(OUT_DATA, 'keys-train.npz'), id = train_keys)\n",
    "numpy.savez(os.path.join(OUT_DATA, 'keys-valid.npz'), id = valid_keys)\n",
    "numpy.savez(os.path.join(OUT_DATA, 'keys-test.npz'),  id = test_keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
